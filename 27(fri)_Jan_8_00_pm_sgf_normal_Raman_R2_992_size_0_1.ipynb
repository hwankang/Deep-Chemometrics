{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNaH4NyX00mGX5J3CsiVPYD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwankang/Deep-Chemometrics/blob/master/27(fri)_Jan_8_00_pm_sgf_normal_Raman_R2_992_size_0_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The program of deep learning with Raman data"
      ],
      "metadata": {
        "id": "m5y8Xea8wm2H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65_oI4G7Ajw3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from scipy.signal import savgol_filter\n",
        "from sklearn.model_selection import train_test_split, cross_validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0SnTgFm4nb5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "filename_a='/content/drive/MyDrive/machine_learning/123_Raman_DATA_csv.csv'\n",
        "X2_df = pd.read_csv(filename_a)\n",
        "X2_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=X2_df.values[:,3:].astype(float)\n",
        "#X_train=X[110:,:]\n",
        "#X_test=X[0:110,:]\n",
        "y=X2_df.values[:,2:5].astype(float)\n",
        "#y_train=Y[110:,:]\n",
        "#y_test=Y[0:110,:]\n",
        "#X_train\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "     X, y, test_size=0.1, random_state=50)"
      ],
      "metadata": {
        "id": "Tlt1uFccOj7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from scipy.signal import savgol_filter\n",
        "#X_train_f=X_train_n.astype(float)\n",
        "#X_test_f=X_test_n.astype(float)\n",
        "X_train_s = savgol_filter(X_train, 17, polyorder=2, deriv=1)\n",
        "X_test_s = savgol_filter(X_test, 17, polyorder=2, deriv=1)"
      ],
      "metadata": {
        "id": "HFE2xEyvRZDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def snv(input_data):\n",
        "  \n",
        "    # Define a new array and populate it with the corrected data  \n",
        "    output_data = np.zeros_like(input_data)\n",
        "    for i in range(input_data.shape[0]):\n",
        " \n",
        "        # Apply correction\n",
        "        output_data[i,:] = (input_data[i,:] - np.mean(input_data[i,:])) / np.std(input_data[i,:])\n",
        " \n",
        "    return output_data"
      ],
      "metadata": {
        "id": "Re5eqvbGdjWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_r=snv(X_train_s)\n",
        "X_test_r=snv(X_test_s)"
      ],
      "metadata": {
        "id": "UihwbjOGRZiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv1D, Reshape#, MaxPooling1D\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.layers.noise import GaussianNoise"
      ],
      "metadata": {
        "id": "Y8AKsfoUd8t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DENSE = 128\n",
        "#DROPOUT = 0.025\n",
        "DROPOUT = 0\n",
        "C1_K  = 8 #Number of kernels/feature extractors for first layer\n",
        "C1_S  = 32 #Width of the convolutional mini networks\n",
        "C2_K  = 16\n",
        "C2_S  = 32\n",
        "\n",
        "#activation='elu'\n",
        "activation='relu'\n",
        "#activation='sigmoid'\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "#The model\n",
        "def make_model():\n",
        "    model = Sequential()\n",
        "    #Adding a bit of GaussianNoise also works as regularization\n",
        "    #model.add(GaussianNoise(0.05, input_shape=(input_dim,)))\n",
        "    model.add(GaussianNoise(0.005, input_shape=(input_dim,)))\n",
        "    ##model.add(GaussianNoise(0.004, input_shape=(input_dim,)))\n",
        "    #First two is number of filter + kernel size\n",
        "    model.add(Reshape((input_dim, 1)))\n",
        "    #model.add(Conv1D(C1_K, (C1_S), activation=activation, border_mode='same'))\n",
        "    #model.add(Conv1D(C2_K, (C2_S), border_mode='same', activation=activation))\n",
        "    model.add(Conv1D(C1_K, (C1_S), activation=activation, padding='same'))\n",
        "    model.add(Conv1D(C2_K, (C2_S), padding='same', activation=activation))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(DROPOUT))\n",
        "    model.add(Dense(DENSE, activation=activation))\n",
        "    model.add(Dense(3, activation='linear'))\n",
        "\n",
        "    #model.compile(loss='mse', optimizer=keras.optimizers.Adadelta(lr=0.01))#, metrics=['mean_absolute_error'])\n",
        "    model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=0.001))#, metrics=['mean_absolute_error'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "o2PxCRCserfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_model()\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "ov7kQISee9dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdlr = ReduceLROnPlateau(patience=25, factor=0.5, min_lr=1e-6, monitor='val_loss', verbose=1)\n",
        "\n",
        "h = model.fit(X_train_r, y_train, epochs=200, batch_size=18*2, validation_data=(X_test_r, y_test), callbacks=[rdlr])"
      ],
      "metadata": {
        "id": "UlCypoOefGma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h.history['loss'], label='loss')\n",
        "plt.plot(h.history['val_loss'], label='val_loss')\n",
        "\n",
        "plt.yscale('log')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "ax2 = plt.gca().twinx()\n",
        "ax2.plot(h.history['lr'], color='r')\n",
        "ax2.set_ylabel('lr',color='r')\n",
        "\n",
        "_ = plt.legend()"
      ],
      "metadata": {
        "id": "jS9RLmpMe9Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(y_train, model.predict(X_train_r))\n",
        "plt.scatter(y_test, model.predict(X_test_r))\n",
        "plt.plot([-5,3],[-5,3]) # Y = PredY line"
      ],
      "metadata": {
        "id": "cjgbISGjgWC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_Y_df=model.predict(X_test_r)\n",
        "Y_df_true=y_test\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "mse= mean_squared_error(Y_df_true, pred_Y_df)\n",
        "rmse=np.sqrt(mse)\n",
        "r2=r2_score(Y_df_true, pred_Y_df)\n",
        "print('MSE : {: 0.3f}, || RMSE : {: 0.3f}, || R2 : {: 0.3f}'.format(mse,rmse,r2))"
      ],
      "metadata": {
        "id": "971F6jIEhNsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#end of the program"
      ],
      "metadata": {
        "id": "BSgiq6ubhWQM"
      }
    }
  ]
}