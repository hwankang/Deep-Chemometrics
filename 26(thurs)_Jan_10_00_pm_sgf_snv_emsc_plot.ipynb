{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOYBOrPKbzanBTj1EpwqjJE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwankang/Deep-Chemometrics/blob/master/26(thurs)_Jan_10_00_pm_sgf_snv_emsc_plot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65_oI4G7Ajw3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##!wget -q https://github.com/EBjerrum/Deep-Chemometrics/blob/master/ChemUtils.py\n",
        "!wget https://github.com/EBjerrum/Deep-Chemometrics/find/master/ChemUtils.py\n",
        "##    ##!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "UE2gr9URApvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ChemUtils\n",
        "from ChemUtils import EmscScaler"
      ],
      "metadata": {
        "id": "y-sIiYoHEIfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0SnTgFm4nb5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "filename_a='/content/drive/MyDrive/machine_learning/A_NIR_DATA_csv.csv'\n",
        "X2_df = pd.read_csv(filename_a,header=0, \n",
        "                   encoding=\"unicode-escape\")\n",
        "X2_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=X2_df.values[:,3:].astype(float)\n",
        "keys=X2_df.keys()\n",
        "key4=keys[3:].astype(float)\n",
        "keys=list(key4)\n",
        "wl=keys"
      ],
      "metadata": {
        "id": "hguZCZizDeuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#insert GlobalStandardScaler\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import scipy #TODO reimplement as Numpy only\n",
        "from scipy import newaxis as nA\n",
        "##import scipy #TODO reimplement as Numpy only\n",
        "##from scipy import newaxis as nA\n",
        "\n",
        "class GlobalStandardScaler(object):\n",
        "    \"\"\"Scales to unit standard deviation and mean centering using global mean and std of X, skleran like API\"\"\"\n",
        "    def __init__(self,with_mean=True, with_std=True, normfact=1.0):\n",
        "        self._with_mean = with_mean\n",
        "        self._with_std = with_std\n",
        "        self.std = None\n",
        "        self.normfact=normfact\n",
        "        self.mean = None\n",
        "        self._fitted = False\n",
        "        \n",
        "    def fit(self,X, y = None):\n",
        "        X = np.array(X)\n",
        "        self.mean = X.mean()\n",
        "        self.std = X.std()\n",
        "        self._fitted = True\n",
        "        \n",
        "    def transform(self,X, y=None):\n",
        "        if self._fitted:\n",
        "            X = np.array(X)\n",
        "            if self._with_mean:\n",
        "                X=X-self.mean\n",
        "            if self._with_std:\n",
        "                X=X/(self.std*self.normfact)\n",
        "            return X\n",
        "        else:\n",
        "            print(\"Scaler is not fitted\")\n",
        "            return\n",
        "            \n",
        "    def inverse_transform(self,X, y=None):\n",
        "        if self._fitted:\n",
        "            X = np.array(X)\n",
        "            if self._with_std:\n",
        "                X=X*self.std*self.normfact\n",
        "            if self._with_mean:\n",
        "                X=X+self.mean\n",
        "            return X\n",
        "        else:\n",
        "            print(\"Scaler is not fitted\")\n",
        "            return\n",
        "            \n",
        "    def fit_transform(self,X, y=None):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RhaHuRDv1uoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xscaler = GlobalStandardScaler()\n",
        "\n",
        "#Calibrate is smaler than test, so they are swapped\n",
        "X_train = xscaler.fit_transform(X) #From instrument 1\n",
        "#X_test = xscaler.transform(X_test_a) #! NB only transform on test set. From instrument 2"
      ],
      "metadata": {
        "id": "bPayvCCL1vfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(wl,X.T)\n",
        "plt.xlabel('nm')\n",
        "plt.ylabel('normalized intensity')\n",
        "plt.title('Normalized training data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LtggfOSH3wcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xscaler = GlobalStandardScaler()\n",
        "X_2=X2_df.values[:,3:].astype(float)\n",
        "#Calibrate is smaler than test, so they are swapped\n",
        "X_c = xscaler.fit_transform(X_2) #From instrument 1\n",
        "#X_test = xscaler.transform(X_test_a) #! NB only transform on test set. From instrument 2"
      ],
      "metadata": {
        "id": "uBNWQHiHGtqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(wl,X_c.T)\n",
        "plt.xlabel('nm')\n",
        "plt.ylabel('normalized intensity')\n",
        "plt.title('Normalized training data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "33EpgSheGtqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use\n",
        "import scipy #TODO reimplement as Numpy only\n",
        "from scipy import newaxis as nA\n",
        "class EmscScaler(object):\n",
        "    def __init__(self,order=1):\n",
        "        self.order = order\n",
        "        self._mx = None\n",
        "        \n",
        "    def mlr(self,x,y):\n",
        "        \"\"\"Multiple linear regression fit of the columns of matrix x \n",
        "        (dependent variables) to constituent vector y (independent variables)\n",
        "        \n",
        "        order -     order of a smoothing polynomial, which can be included \n",
        "                    in the set of independent variables. If order is\n",
        "                    not specified, no background will be included.\n",
        "        b -         fit coeffs\n",
        "        f -         fit result (m x 1 column vector)\n",
        "        r -         residual   (m x 1 column vector)\n",
        "        \"\"\"\n",
        "        \n",
        "        if self.order > 0:\n",
        "            s= np.ones((len(y),1))\n",
        "            for j in range(self.order):\n",
        "                s= np.concatenate((s,(np.arange(0,1+(1.0/(len(y)-1)),1.0/(len(y)-1))**j)[:,nA]),1)\n",
        "            X= np.concatenate((x, s),1)\n",
        "        else:\n",
        "            X = x\n",
        "        b = np.dot(np.dot(np.linalg.pinv(np.dot(np.transpose(X),X)),np.transpose(X)),y)\n",
        "        f = np.dot(X,b)\n",
        "        r = y - f\n",
        "\n",
        "        return b,f,r\n",
        "\n",
        "    \n",
        "    def inverse_transform(self, X, y=None):\n",
        "        print(\"Warning: inverse transform not possible with Emsc\")\n",
        "        return X\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"fit to X (get average spectrum), y is a passthrough for pipeline compatibility\"\"\"\n",
        "        self._mx = np.mean(X,axis=0)[:,nA]\n",
        "        \n",
        "    def transform(self, X, y=None, copy=None):\n",
        "        if type(self._mx) == type(None):\n",
        "            print(\"EMSC not fit yet. run .fit method on reference spectra\")\n",
        "        else:\n",
        "            #do fitting\n",
        "            corr = np.zeros(X.shape)\n",
        "            for i in range(len(X)):\n",
        "                b,f,r = self.mlr(self._mx, X[i,:][:,nA])\n",
        "                corr[i,:] = np.reshape((r/b[0,0]) + self._mx, (corr.shape[1],))\n",
        "            return corr\n",
        "    \n",
        "    def fit_transform(self, X, y=None):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)\n",
        "          "
      ],
      "metadata": {
        "id": "gKazIIeD-xQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use\n",
        "#EMSC rescaling\n",
        "##from ChemUtils import EmscScaler\n",
        "\n",
        "emsc = EmscScaler()\n",
        "\n",
        "emsc.fit(X_train)\n",
        "\n",
        "#X_train_emsc = emsc.transform(X_train_a)\n",
        "X_train_emsc = emsc.fit_transform(X_train)\n",
        "\n",
        "#_ = plt.plot(dataset['axisscale'],X_train_emsc.T)\n",
        "#X_train_emsc[0,:]"
      ],
      "metadata": {
        "id": "w4kj-ef4-2U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(wl,X_train_emsc.T)\n",
        "plt.xlabel('nm')\n",
        "plt.ylabel('normalized intensity')\n",
        "plt.title('Normalized training data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w05BfVOHMqJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#delete\n",
        "import scipy #TODO reimplement as Numpy only\n",
        "from scipy import newaxis as nA\n",
        "class SavGolFilt(object):\n",
        "    \"\"\"Applies a Savitsky-Golay filter of order k and frame width F.\n",
        "    The order must be odd and the frame width (F) a positive integer of\n",
        "    a value greater than k\n",
        "    \"\"\"\n",
        "    #TODO use the scipy implementation\n",
        "    def __init__(self, order=1, width=11):\n",
        "        self.k = order\n",
        "        self.frame = width\n",
        "\n",
        "    def transform(self,myarray,y=None):\n",
        "        \"\"\"Applies a Savitsky-Golay filter of order k and frame width F.\n",
        "        The order must be odd and the frame width (F) a positive integer of\n",
        "        a value greater than k\n",
        "        \"\"\"\n",
        "        frange = scipy.arange(-(self.frame-1)/2,((self.frame-1)/2)+1)\n",
        "        f, vande = 0, scipy.zeros((self.frame,self.frame))\n",
        "        while f < self.frame:    # compute Vandemonde matrix\n",
        "            vande[f,:] = frange**f\n",
        "            f = f+1\n",
        "        vande = scipy.transpose(vande,(1,0))\n",
        "        vande = vande[:,0:self.k+1]\n",
        "        Q,R = scipy.linalg.qr(vande,vande.shape[1]) # Do QR decomposition\n",
        "    \n",
        "    #    print vande.shape\n",
        "    #    print Q.shape\n",
        "    #    print R[0:vande.shape[1]]\n",
        "        G = scipy.dot(vande,scipy.dot(scipy.linalg.inv(R[0:vande.shape[1]]), \n",
        "        scipy.transpose(scipy.linalg.inv(R[0:vande.shape[1]])))) # Find the matrix of differentiators\n",
        "    \n",
        "        B = scipy.dot(G,scipy.transpose(vande)) # Projection matrix\n",
        "    \n",
        "        myarray = scipy.transpose(myarray)\n",
        "        extract_array, extract_B = myarray[0:self.frame,:], B[(((self.frame-1)/2)+1):self.frame,:]\n",
        "        start_array = scipy.dot(extract_B[::-1],extract_array[::-1]) # first bins\n",
        "\n",
        "        array_size = myarray.shape\n",
        "        last, mid_array = (self.frame-1)/2, scipy.zeros((array_size[0],array_size[1]),'d')\n",
        "        extract_B = scipy.reshape(B[((self.frame-1)/2),:],(self.frame,1))\n",
        "        while last < array_size[0]-((self.frame-1)/2):\n",
        "            mid_array[last,:] = sum((extract_B*myarray[last-((self.frame-1)/2):last+((self.frame-1)/2)+1,:]),0) #middle bit\n",
        "            last = last+1\n",
        "        \n",
        "        extract_array, extract_B = myarray[array_size[0]-self.frame:array_size[0],:], B[0:(self.frame-1)/2,:]\n",
        "        end_array = scipy.dot(extract_B[::-1],extract_array[::-1]) # last bins\n",
        "\n",
        "        mid_array[0:(self.frame-1)/2,:], mid_array[array_size[0]-((self.frame-1)/2):array_size[0],:] = start_array, end_array\n",
        "        return scipy.transpose(mid_array)\n",
        "\n",
        "    def fit(self, X,y=None):\n",
        "        print(\"Fit not needed for filter\")\n",
        "        pass\n",
        "        \n",
        "    def fit_transform(self, X,y=None):\n",
        "        return self.transform(X)\n",
        "\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "VKYNsBUf7aSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use\n",
        "#EMSC rescaling\n",
        "##from ChemUtils import EmscScaler\n",
        "from scipy import linalg\n",
        "\n",
        "sgf = SavGolFilt()\n",
        "\n",
        "sgf.fit(X)\n",
        "\n",
        "#X_train_emsc = emsc.transform(X_train_a)\n",
        "X_sgf = sgf.transform(X)\n",
        "\n",
        "#_ = plt.plot(dataset['axisscale'],X_train_emsc.T)\n",
        "#X_train_emsc[0,:]"
      ],
      "metadata": {
        "id": "WQSeRnTkX8Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import savgol_filter"
      ],
      "metadata": {
        "id": "xJuMZg_hJR09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X2 = savgol_filter(X, 11, polyorder=2, deriv=1)\n",
        "plt.plot(wl,X2.T)\n",
        "plt.xlabel('nm')\n",
        "plt.ylabel('normalized intensity')\n",
        "plt.title('SGFilter data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z9gJFzKZDvGF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}