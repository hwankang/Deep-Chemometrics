{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMvMaHTRUt3AamON2d030sy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwankang/Deep-Chemometrics/blob/master/27(fri)_Jan_5_00_pm_sgf_normal_R2_906_A_NIR_size_0_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65_oI4G7Ajw3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from scipy.signal import savgol_filter\n",
        "from sklearn.model_selection import train_test_split, cross_validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0SnTgFm4nb5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "filename_a='/content/drive/MyDrive/machine_learning/A_NIR_DATA_csv.csv'\n",
        "X2_df = pd.read_csv(filename_a,header=0, \n",
        "                   encoding=\"unicode-escape\")\n",
        "X2_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=X2_df.values[:,3:].astype(float)\n",
        "#X_train=X[110:,:]\n",
        "#X_test=X[0:110,:]\n",
        "y=X2_df.values[:,2:3].astype(float)\n",
        "#y_train=Y[110:,:]\n",
        "#y_test=Y[0:110,:]\n",
        "#X_train\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "     X, y, test_size=0.1, random_state=46)"
      ],
      "metadata": {
        "id": "Tlt1uFccOj7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from scipy.signal import savgol_filter\n",
        "#X_train_f=X_train_n.astype(float)\n",
        "#X_test_f=X_test_n.astype(float)\n",
        "X_train_s = savgol_filter(X_train, 17, polyorder=2, deriv=1)\n",
        "X_test_s = savgol_filter(X_test, 17, polyorder=2, deriv=1)"
      ],
      "metadata": {
        "id": "HFE2xEyvRZDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def snv(input_data):\n",
        "  \n",
        "    # Define a new array and populate it with the corrected data  \n",
        "    output_data = np.zeros_like(input_data)\n",
        "    for i in range(input_data.shape[0]):\n",
        " \n",
        "        # Apply correction\n",
        "        output_data[i,:] = (input_data[i,:] - np.mean(input_data[i,:])) / np.std(input_data[i,:])\n",
        " \n",
        "    return output_data"
      ],
      "metadata": {
        "id": "Re5eqvbGdjWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_r=snv(X_train_s)\n",
        "X_test_r=snv(X_test_s)"
      ],
      "metadata": {
        "id": "UihwbjOGRZiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv1D, Reshape#, MaxPooling1D\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.layers.noise import GaussianNoise"
      ],
      "metadata": {
        "id": "Y8AKsfoUd8t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DENSE = 128\n",
        "#DROPOUT = 0.025\n",
        "DROPOUT = 0\n",
        "C1_K  = 8 #Number of kernels/feature extractors for first layer\n",
        "C1_S  = 32 #Width of the convolutional mini networks\n",
        "C2_K  = 16\n",
        "C2_S  = 32\n",
        "\n",
        "#activation='elu'\n",
        "activation='relu'\n",
        "#activation='sigmoid'\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "#The model\n",
        "def make_model():\n",
        "    model = Sequential()\n",
        "    #Adding a bit of GaussianNoise also works as regularization\n",
        "    #model.add(GaussianNoise(0.05, input_shape=(input_dim,)))\n",
        "    model.add(GaussianNoise(0.005, input_shape=(input_dim,)))\n",
        "    ##model.add(GaussianNoise(0.004, input_shape=(input_dim,)))\n",
        "    #First two is number of filter + kernel size\n",
        "    model.add(Reshape((input_dim, 1)))\n",
        "    #model.add(Conv1D(C1_K, (C1_S), activation=activation, border_mode='same'))\n",
        "    #model.add(Conv1D(C2_K, (C2_S), border_mode='same', activation=activation))\n",
        "    model.add(Conv1D(C1_K, (C1_S), activation=activation, padding='same'))\n",
        "    model.add(Conv1D(C2_K, (C2_S), padding='same', activation=activation))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(DROPOUT))\n",
        "    model.add(Dense(DENSE, activation=activation))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    #model.compile(loss='mse', optimizer=keras.optimizers.Adadelta(lr=0.01))#, metrics=['mean_absolute_error'])\n",
        "    model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=0.001))#, metrics=['mean_absolute_error'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "o2PxCRCserfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_model()\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "ov7kQISee9dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdlr = ReduceLROnPlateau(patience=25, factor=0.5, min_lr=1e-6, monitor='val_loss', verbose=1)\n",
        "\n",
        "h = model.fit(X_train_r, y_train, epochs=600, batch_size=18*2, validation_data=(X_test_r, y_test), callbacks=[rdlr])"
      ],
      "metadata": {
        "id": "UlCypoOefGma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h.history['loss'], label='loss')\n",
        "plt.plot(h.history['val_loss'], label='val_loss')\n",
        "\n",
        "plt.yscale('log')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "ax2 = plt.gca().twinx()\n",
        "ax2.plot(h.history['lr'], color='r')\n",
        "ax2.set_ylabel('lr',color='r')\n",
        "\n",
        "_ = plt.legend()"
      ],
      "metadata": {
        "id": "jS9RLmpMe9Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(y_train, model.predict(X_train_r))\n",
        "plt.scatter(y_test, model.predict(X_test_r))\n",
        "plt.plot([-5,3],[-5,3]) # Y = PredY line"
      ],
      "metadata": {
        "id": "cjgbISGjgWC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_Y_df=model.predict(X_test_r)\n",
        "Y_df_true=y_test\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "mse= mean_squared_error(Y_df_true, pred_Y_df)\n",
        "rmse=np.sqrt(mse)\n",
        "r2=r2_score(Y_df_true, pred_Y_df)\n",
        "print('MSE : {: 0.3f}, || RMSE : {: 0.3f}, || R2 : {: 0.3f}'.format(mse,rmse,r2))"
      ],
      "metadata": {
        "id": "971F6jIEhNsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#end of the program"
      ],
      "metadata": {
        "id": "BSgiq6ubhWQM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pv5DhHamhVvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=X2_df.values[:,3:].astype(float)\n",
        "keys=X2_df.keys()\n",
        "key4=keys[3:].astype(float)\n",
        "keys=list(key4)\n",
        "wl=keys"
      ],
      "metadata": {
        "id": "hguZCZizDeuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#insert GlobalStandardScaler\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import scipy #TODO reimplement as Numpy only\n",
        "from scipy import newaxis as nA\n",
        "##import scipy #TODO reimplement as Numpy only\n",
        "##from scipy import newaxis as nA\n",
        "\n",
        "class GlobalStandardScaler(object):\n",
        "    \"\"\"Scales to unit standard deviation and mean centering using global mean and std of X, skleran like API\"\"\"\n",
        "    def __init__(self,with_mean=True, with_std=True, normfact=1.0):\n",
        "        self._with_mean = with_mean\n",
        "        self._with_std = with_std\n",
        "        self.std = None\n",
        "        self.normfact=normfact\n",
        "        self.mean = None\n",
        "        self._fitted = False\n",
        "        \n",
        "    def fit(self,X, y = None):\n",
        "        X = np.array(X)\n",
        "        self.mean = X.mean()\n",
        "        self.std = X.std()\n",
        "        self._fitted = True\n",
        "        \n",
        "    def transform(self,X, y=None):\n",
        "        if self._fitted:\n",
        "            X = np.array(X)\n",
        "            if self._with_mean:\n",
        "                X=X-self.mean\n",
        "            if self._with_std:\n",
        "                X=X/(self.std*self.normfact)\n",
        "            return X\n",
        "        else:\n",
        "            print(\"Scaler is not fitted\")\n",
        "            return\n",
        "            \n",
        "    def inverse_transform(self,X, y=None):\n",
        "        if self._fitted:\n",
        "            X = np.array(X)\n",
        "            if self._with_std:\n",
        "                X=X*self.std*self.normfact\n",
        "            if self._with_mean:\n",
        "                X=X+self.mean\n",
        "            return X\n",
        "        else:\n",
        "            print(\"Scaler is not fitted\")\n",
        "            return\n",
        "            \n",
        "    def fit_transform(self,X, y=None):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RhaHuRDv1uoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xscaler = GlobalStandardScaler()\n",
        "\n",
        "#Calibrate is smaler than test, so they are swapped\n",
        "X_train = xscaler.fit_transform(X) #From instrument 1\n",
        "#X_test = xscaler.transform(X_test_a) #! NB only transform on test set. From instrument 2"
      ],
      "metadata": {
        "id": "bPayvCCL1vfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(wl,X.T)\n",
        "plt.xlabel('nm')\n",
        "plt.ylabel('normalized intensity')\n",
        "plt.title('Normalized training data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LtggfOSH3wcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xscaler = GlobalStandardScaler()\n",
        "X_2=X2_df.values[:,3:].astype(float)\n",
        "#Calibrate is smaler than test, so they are swapped\n",
        "X_c = xscaler.fit_transform(X_2) #From instrument 1\n",
        "#X_test = xscaler.transform(X_test_a) #! NB only transform on test set. From instrument 2"
      ],
      "metadata": {
        "id": "uBNWQHiHGtqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(wl,X_c.T)\n",
        "plt.xlabel('nm')\n",
        "plt.ylabel('normalized intensity')\n",
        "plt.title('Normalized training data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "33EpgSheGtqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use\n",
        "import scipy #TODO reimplement as Numpy only\n",
        "from scipy import newaxis as nA\n",
        "class EmscScaler(object):\n",
        "    def __init__(self,order=1):\n",
        "        self.order = order\n",
        "        self._mx = None\n",
        "        \n",
        "    def mlr(self,x,y):\n",
        "        \"\"\"Multiple linear regression fit of the columns of matrix x \n",
        "        (dependent variables) to constituent vector y (independent variables)\n",
        "        \n",
        "        order -     order of a smoothing polynomial, which can be included \n",
        "                    in the set of independent variables. If order is\n",
        "                    not specified, no background will be included.\n",
        "        b -         fit coeffs\n",
        "        f -         fit result (m x 1 column vector)\n",
        "        r -         residual   (m x 1 column vector)\n",
        "        \"\"\"\n",
        "        \n",
        "        if self.order > 0:\n",
        "            s= np.ones((len(y),1))\n",
        "            for j in range(self.order):\n",
        "                s= np.concatenate((s,(np.arange(0,1+(1.0/(len(y)-1)),1.0/(len(y)-1))**j)[:,nA]),1)\n",
        "            X= np.concatenate((x, s),1)\n",
        "        else:\n",
        "            X = x\n",
        "        b = np.dot(np.dot(np.linalg.pinv(np.dot(np.transpose(X),X)),np.transpose(X)),y)\n",
        "        f = np.dot(X,b)\n",
        "        r = y - f\n",
        "\n",
        "        return b,f,r\n",
        "\n",
        "    \n",
        "    def inverse_transform(self, X, y=None):\n",
        "        print(\"Warning: inverse transform not possible with Emsc\")\n",
        "        return X\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"fit to X (get average spectrum), y is a passthrough for pipeline compatibility\"\"\"\n",
        "        self._mx = np.mean(X,axis=0)[:,nA]\n",
        "        \n",
        "    def transform(self, X, y=None, copy=None):\n",
        "        if type(self._mx) == type(None):\n",
        "            print(\"EMSC not fit yet. run .fit method on reference spectra\")\n",
        "        else:\n",
        "            #do fitting\n",
        "            corr = np.zeros(X.shape)\n",
        "            for i in range(len(X)):\n",
        "                b,f,r = self.mlr(self._mx, X[i,:][:,nA])\n",
        "                corr[i,:] = np.reshape((r/b[0,0]) + self._mx, (corr.shape[1],))\n",
        "            return corr\n",
        "    \n",
        "    def fit_transform(self, X, y=None):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)\n",
        "          "
      ],
      "metadata": {
        "id": "gKazIIeD-xQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use\n",
        "#EMSC rescaling\n",
        "##from ChemUtils import EmscScaler\n",
        "\n",
        "emsc = EmscScaler()\n",
        "\n",
        "emsc.fit(X_train)\n",
        "\n",
        "#X_train_emsc = emsc.transform(X_train_a)\n",
        "X_train_emsc = emsc.fit_transform(X_train)\n",
        "\n",
        "#_ = plt.plot(dataset['axisscale'],X_train_emsc.T)\n",
        "#X_train_emsc[0,:]"
      ],
      "metadata": {
        "id": "w4kj-ef4-2U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(wl,X_train_emsc.T)\n",
        "plt.xlabel('nm')\n",
        "plt.ylabel('normalized intensity')\n",
        "plt.title('Normalized training data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w05BfVOHMqJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#delete\n",
        "import scipy #TODO reimplement as Numpy only\n",
        "from scipy import newaxis as nA\n",
        "class SavGolFilt(object):\n",
        "    \"\"\"Applies a Savitsky-Golay filter of order k and frame width F.\n",
        "    The order must be odd and the frame width (F) a positive integer of\n",
        "    a value greater than k\n",
        "    \"\"\"\n",
        "    #TODO use the scipy implementation\n",
        "    def __init__(self, order=1, width=11):\n",
        "        self.k = order\n",
        "        self.frame = width\n",
        "\n",
        "    def transform(self,myarray,y=None):\n",
        "        \"\"\"Applies a Savitsky-Golay filter of order k and frame width F.\n",
        "        The order must be odd and the frame width (F) a positive integer of\n",
        "        a value greater than k\n",
        "        \"\"\"\n",
        "        frange = scipy.arange(-(self.frame-1)/2,((self.frame-1)/2)+1)\n",
        "        f, vande = 0, scipy.zeros((self.frame,self.frame))\n",
        "        while f < self.frame:    # compute Vandemonde matrix\n",
        "            vande[f,:] = frange**f\n",
        "            f = f+1\n",
        "        vande = scipy.transpose(vande,(1,0))\n",
        "        vande = vande[:,0:self.k+1]\n",
        "        Q,R = scipy.linalg.qr(vande,vande.shape[1]) # Do QR decomposition\n",
        "    \n",
        "    #    print vande.shape\n",
        "    #    print Q.shape\n",
        "    #    print R[0:vande.shape[1]]\n",
        "        G = scipy.dot(vande,scipy.dot(scipy.linalg.inv(R[0:vande.shape[1]]), \n",
        "        scipy.transpose(scipy.linalg.inv(R[0:vande.shape[1]])))) # Find the matrix of differentiators\n",
        "    \n",
        "        B = scipy.dot(G,scipy.transpose(vande)) # Projection matrix\n",
        "    \n",
        "        myarray = scipy.transpose(myarray)\n",
        "        extract_array, extract_B = myarray[0:self.frame,:], B[(((self.frame-1)/2)+1):self.frame,:]\n",
        "        start_array = scipy.dot(extract_B[::-1],extract_array[::-1]) # first bins\n",
        "\n",
        "        array_size = myarray.shape\n",
        "        last, mid_array = (self.frame-1)/2, scipy.zeros((array_size[0],array_size[1]),'d')\n",
        "        extract_B = scipy.reshape(B[((self.frame-1)/2),:],(self.frame,1))\n",
        "        while last < array_size[0]-((self.frame-1)/2):\n",
        "            mid_array[last,:] = sum((extract_B*myarray[last-((self.frame-1)/2):last+((self.frame-1)/2)+1,:]),0) #middle bit\n",
        "            last = last+1\n",
        "        \n",
        "        extract_array, extract_B = myarray[array_size[0]-self.frame:array_size[0],:], B[0:(self.frame-1)/2,:]\n",
        "        end_array = scipy.dot(extract_B[::-1],extract_array[::-1]) # last bins\n",
        "\n",
        "        mid_array[0:(self.frame-1)/2,:], mid_array[array_size[0]-((self.frame-1)/2):array_size[0],:] = start_array, end_array\n",
        "        return scipy.transpose(mid_array)\n",
        "\n",
        "    def fit(self, X,y=None):\n",
        "        print(\"Fit not needed for filter\")\n",
        "        pass\n",
        "        \n",
        "    def fit_transform(self, X,y=None):\n",
        "        return self.transform(X)\n",
        "\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "VKYNsBUf7aSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use\n",
        "#EMSC rescaling\n",
        "##from ChemUtils import EmscScaler\n",
        "from scipy import linalg\n",
        "\n",
        "sgf = SavGolFilt()\n",
        "\n",
        "sgf.fit(X)\n",
        "\n",
        "#X_train_emsc = emsc.transform(X_train_a)\n",
        "X_sgf = sgf.transform(X)\n",
        "\n",
        "#_ = plt.plot(dataset['axisscale'],X_train_emsc.T)\n",
        "#X_train_emsc[0,:]"
      ],
      "metadata": {
        "id": "WQSeRnTkX8Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import savgol_filter"
      ],
      "metadata": {
        "id": "xJuMZg_hJR09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X2 = savgol_filter(X, 11, polyorder=2, deriv=1)\n",
        "plt.plot(wl,X2.T)\n",
        "plt.xlabel('nm')\n",
        "plt.ylabel('normalized intensity')\n",
        "plt.title('SGFilter data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z9gJFzKZDvGF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}